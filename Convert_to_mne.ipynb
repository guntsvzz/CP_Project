{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "pickle.format_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exp1_Ati.csv', 'exp2_Tonson.csv', 'exp3_Pyae.csv', 'exp4_Duc.csv', 'exp5_And.csv', 'exp6_Sayaka.csv', 'exp7_Suyoga.csv', 'exp8_Arti.csv', 'exp9_Amanda.csv', 'exp10_Sapna.csv', 'exp11_Data.csv', 'exp12_Jirasak.csv', 'exp13_Max.csv', 'exp14_Ayush.csv', 'exp15_Dipesh.csv', 'exp16_Shashank.csv', 'exp17_Mi.csv']\n"
     ]
    }
   ],
   "source": [
    "main_path = os.getcwd()\n",
    "all_file = os.listdir()\n",
    "file_name = list()\n",
    "for file in all_file:\n",
    "    if file[0:3] == 'exp':\n",
    "        file_name.append(file)\n",
    "file_name = sorted(file_name)\n",
    "file = file_name[8:] + file_name[0:8]\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fp1</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>T3</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>T6</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3203.250850</td>\n",
       "      <td>-7278.934989</td>\n",
       "      <td>-22030.236963</td>\n",
       "      <td>-9343.319755</td>\n",
       "      <td>-3711.417760</td>\n",
       "      <td>2255.693347</td>\n",
       "      <td>-12633.653001</td>\n",
       "      <td>3538.079982</td>\n",
       "      <td>-22537.129824</td>\n",
       "      <td>-5153.306443</td>\n",
       "      <td>-16958.246166</td>\n",
       "      <td>-12598.918390</td>\n",
       "      <td>-25105.434669</td>\n",
       "      <td>-17961.593623</td>\n",
       "      <td>-23601.229322</td>\n",
       "      <td>-12943.850511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3201.261544</td>\n",
       "      <td>-7280.209038</td>\n",
       "      <td>-22023.464384</td>\n",
       "      <td>-9339.251738</td>\n",
       "      <td>-3717.095103</td>\n",
       "      <td>2254.843981</td>\n",
       "      <td>-12623.482957</td>\n",
       "      <td>3549.121743</td>\n",
       "      <td>-22528.434995</td>\n",
       "      <td>-5154.111106</td>\n",
       "      <td>-16954.200501</td>\n",
       "      <td>-12597.577285</td>\n",
       "      <td>-25057.289011</td>\n",
       "      <td>-17954.262251</td>\n",
       "      <td>-23595.775496</td>\n",
       "      <td>-12940.073066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3196.210050</td>\n",
       "      <td>-7273.592922</td>\n",
       "      <td>-22024.492565</td>\n",
       "      <td>-9336.636583</td>\n",
       "      <td>-3709.696676</td>\n",
       "      <td>2258.263798</td>\n",
       "      <td>-12628.355638</td>\n",
       "      <td>3541.052764</td>\n",
       "      <td>-22536.682789</td>\n",
       "      <td>-5150.914806</td>\n",
       "      <td>-16955.631012</td>\n",
       "      <td>-12597.934913</td>\n",
       "      <td>-25113.861276</td>\n",
       "      <td>-17958.620841</td>\n",
       "      <td>-23597.206008</td>\n",
       "      <td>-12945.079857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3200.680399</td>\n",
       "      <td>-7275.045785</td>\n",
       "      <td>-22027.152422</td>\n",
       "      <td>-9340.548139</td>\n",
       "      <td>-3711.887146</td>\n",
       "      <td>2257.839114</td>\n",
       "      <td>-12625.986353</td>\n",
       "      <td>3540.337508</td>\n",
       "      <td>-22531.653646</td>\n",
       "      <td>-5155.362803</td>\n",
       "      <td>-16966.918643</td>\n",
       "      <td>-12605.355693</td>\n",
       "      <td>-25079.171369</td>\n",
       "      <td>-17968.075629</td>\n",
       "      <td>-23611.891104</td>\n",
       "      <td>-12950.332516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3200.434530</td>\n",
       "      <td>-7280.454907</td>\n",
       "      <td>-22023.263219</td>\n",
       "      <td>-9337.888281</td>\n",
       "      <td>-3719.866719</td>\n",
       "      <td>2250.083059</td>\n",
       "      <td>-12625.360504</td>\n",
       "      <td>3544.740801</td>\n",
       "      <td>-22535.162870</td>\n",
       "      <td>-5155.876894</td>\n",
       "      <td>-16955.586309</td>\n",
       "      <td>-12599.141908</td>\n",
       "      <td>-25085.094581</td>\n",
       "      <td>-17956.765647</td>\n",
       "      <td>-23594.814371</td>\n",
       "      <td>-12943.895214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>-1023.687544</td>\n",
       "      <td>-4436.709516</td>\n",
       "      <td>-24608.175410</td>\n",
       "      <td>-7672.683319</td>\n",
       "      <td>-870.712205</td>\n",
       "      <td>3996.514260</td>\n",
       "      <td>-11068.561503</td>\n",
       "      <td>2068.966874</td>\n",
       "      <td>-19891.152667</td>\n",
       "      <td>-2561.196990</td>\n",
       "      <td>-15042.232280</td>\n",
       "      <td>-10727.473882</td>\n",
       "      <td>-23593.182694</td>\n",
       "      <td>-15365.058525</td>\n",
       "      <td>-21944.339209</td>\n",
       "      <td>-10726.311591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>-1016.534986</td>\n",
       "      <td>-4433.557920</td>\n",
       "      <td>-24602.051032</td>\n",
       "      <td>-7667.207142</td>\n",
       "      <td>-870.868667</td>\n",
       "      <td>3997.363627</td>\n",
       "      <td>-11064.828761</td>\n",
       "      <td>2070.620903</td>\n",
       "      <td>-19898.282873</td>\n",
       "      <td>-2560.526438</td>\n",
       "      <td>-15037.672524</td>\n",
       "      <td>-10726.758626</td>\n",
       "      <td>-23615.623846</td>\n",
       "      <td>-15353.480322</td>\n",
       "      <td>-21941.701703</td>\n",
       "      <td>-10729.016153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>-1015.238585</td>\n",
       "      <td>-4427.813521</td>\n",
       "      <td>-24602.676881</td>\n",
       "      <td>-7664.524932</td>\n",
       "      <td>-859.826906</td>\n",
       "      <td>4002.616287</td>\n",
       "      <td>-11067.220398</td>\n",
       "      <td>2069.458612</td>\n",
       "      <td>-19891.867923</td>\n",
       "      <td>-2558.313615</td>\n",
       "      <td>-15045.048600</td>\n",
       "      <td>-10730.424312</td>\n",
       "      <td>-23618.797793</td>\n",
       "      <td>-15361.482246</td>\n",
       "      <td>-21954.531605</td>\n",
       "      <td>-10730.089036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>-1018.189015</td>\n",
       "      <td>-4432.820312</td>\n",
       "      <td>-24600.844038</td>\n",
       "      <td>-7668.280026</td>\n",
       "      <td>-871.963903</td>\n",
       "      <td>4003.420949</td>\n",
       "      <td>-11061.364241</td>\n",
       "      <td>2073.280760</td>\n",
       "      <td>-19889.163362</td>\n",
       "      <td>-2559.073574</td>\n",
       "      <td>-15034.945611</td>\n",
       "      <td>-10725.953964</td>\n",
       "      <td>-23582.744429</td>\n",
       "      <td>-15350.127560</td>\n",
       "      <td>-21938.706570</td>\n",
       "      <td>-10721.908298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>-1012.243451</td>\n",
       "      <td>-4424.617222</td>\n",
       "      <td>-24602.632177</td>\n",
       "      <td>-7664.100249</td>\n",
       "      <td>-860.475106</td>\n",
       "      <td>4003.309191</td>\n",
       "      <td>-11065.476962</td>\n",
       "      <td>2068.184563</td>\n",
       "      <td>-19896.986472</td>\n",
       "      <td>-2556.748993</td>\n",
       "      <td>-15037.873690</td>\n",
       "      <td>-10727.071551</td>\n",
       "      <td>-23631.024197</td>\n",
       "      <td>-15354.642612</td>\n",
       "      <td>-21942.439311</td>\n",
       "      <td>-10726.669219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fp1          Fp2            F7           F3           F4  \\\n",
       "0     -3203.250850 -7278.934989 -22030.236963 -9343.319755 -3711.417760   \n",
       "1     -3201.261544 -7280.209038 -22023.464384 -9339.251738 -3717.095103   \n",
       "2     -3196.210050 -7273.592922 -22024.492565 -9336.636583 -3709.696676   \n",
       "3     -3200.680399 -7275.045785 -22027.152422 -9340.548139 -3711.887146   \n",
       "4     -3200.434530 -7280.454907 -22023.263219 -9337.888281 -3719.866719   \n",
       "...            ...          ...           ...          ...          ...   \n",
       "44995 -1023.687544 -4436.709516 -24608.175410 -7672.683319  -870.712205   \n",
       "44996 -1016.534986 -4433.557920 -24602.051032 -7667.207142  -870.868667   \n",
       "44997 -1015.238585 -4427.813521 -24602.676881 -7664.524932  -859.826906   \n",
       "44998 -1018.189015 -4432.820312 -24600.844038 -7668.280026  -871.963903   \n",
       "44999 -1012.243451 -4424.617222 -24602.632177 -7664.100249  -860.475106   \n",
       "\n",
       "                F8            T3           C3            C4           T4  \\\n",
       "0      2255.693347 -12633.653001  3538.079982 -22537.129824 -5153.306443   \n",
       "1      2254.843981 -12623.482957  3549.121743 -22528.434995 -5154.111106   \n",
       "2      2258.263798 -12628.355638  3541.052764 -22536.682789 -5150.914806   \n",
       "3      2257.839114 -12625.986353  3540.337508 -22531.653646 -5155.362803   \n",
       "4      2250.083059 -12625.360504  3544.740801 -22535.162870 -5155.876894   \n",
       "...            ...           ...          ...           ...          ...   \n",
       "44995  3996.514260 -11068.561503  2068.966874 -19891.152667 -2561.196990   \n",
       "44996  3997.363627 -11064.828761  2070.620903 -19898.282873 -2560.526438   \n",
       "44997  4002.616287 -11067.220398  2069.458612 -19891.867923 -2558.313615   \n",
       "44998  4003.420949 -11061.364241  2073.280760 -19889.163362 -2559.073574   \n",
       "44999  4003.309191 -11065.476962  2068.184563 -19896.986472 -2556.748993   \n",
       "\n",
       "                 T5            P3            P4            T6            O1  \\\n",
       "0     -16958.246166 -12598.918390 -25105.434669 -17961.593623 -23601.229322   \n",
       "1     -16954.200501 -12597.577285 -25057.289011 -17954.262251 -23595.775496   \n",
       "2     -16955.631012 -12597.934913 -25113.861276 -17958.620841 -23597.206008   \n",
       "3     -16966.918643 -12605.355693 -25079.171369 -17968.075629 -23611.891104   \n",
       "4     -16955.586309 -12599.141908 -25085.094581 -17956.765647 -23594.814371   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "44995 -15042.232280 -10727.473882 -23593.182694 -15365.058525 -21944.339209   \n",
       "44996 -15037.672524 -10726.758626 -23615.623846 -15353.480322 -21941.701703   \n",
       "44997 -15045.048600 -10730.424312 -23618.797793 -15361.482246 -21954.531605   \n",
       "44998 -15034.945611 -10725.953964 -23582.744429 -15350.127560 -21938.706570   \n",
       "44999 -15037.873690 -10727.071551 -23631.024197 -15354.642612 -21942.439311   \n",
       "\n",
       "                 O2  \n",
       "0     -12943.850511  \n",
       "1     -12940.073066  \n",
       "2     -12945.079857  \n",
       "3     -12950.332516  \n",
       "4     -12943.895214  \n",
       "...             ...  \n",
       "44995 -10726.311591  \n",
       "44996 -10729.016153  \n",
       "44997 -10730.089036  \n",
       "44998 -10721.908298  \n",
       "44999 -10726.669219  \n",
       "\n",
       "[45000 rows x 16 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(main_path + '/' + file[0])\n",
    "df1 = df1.drop(columns=['Unnamed: 0', '0', '17', '18', '19', '20', '21', '22',\n",
    "       '23', '24', '25', '26', '27', '28', '29', '30', '31'])\n",
    "df1.columns = ['Fp1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'T3', 'C3', 'C4', 'T4', 'T5', 'P3', 'P4', 'T6', 'O1', 'O2']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns and save it into the new file.\n",
    "for i in range(len(file)):\n",
    "    converted_signal_path = main_path + '/Converted_signal/' + 'Conv_' + file[i]\n",
    "    df = pd.read_csv(main_path + '/' + file[i])\n",
    "    df = df.drop(columns=['Unnamed: 0', '0', '17', '18', '19', '20', '21', '22',\n",
    "        '23', '24', '25', '26', '27', '28', '29', '30', '31'])\n",
    "    df.columns = ['Fp1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'T3', 'C3', 'C4', 'T4', 'T5', 'P3', 'P4', 'T6', 'O1', 'O2']\n",
    "    df = df.set_index(df.columns[0])\n",
    "    df.to_csv(converted_signal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_raw(df):\n",
    "    ch_names = ['Fp1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'T3', 'C3', 'C4', 'T4', 'T5', 'P3', 'P4', 'T6', 'O1', 'O2']\n",
    "    ch_types = ['eeg'] * len(ch_names)\n",
    "    df = df.T\n",
    "    sampling_rate = 250 #Hz\n",
    "    info = mne.create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sampling_rate)\n",
    "    raw = mne.io.RawArray(df, info)\n",
    "    raw.set_montage('standard_1020')\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import Epochs, find_events\n",
    "\n",
    "def getEpochs(raw, event_id, tmin, tmax, picks):\n",
    "\n",
    "    #epoching\n",
    "    events = find_events(raw)\n",
    "    epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                    tmin=tmin, tmax=tmax, baseline=None, preload=True,verbose=False, picks=picks)  #8 channels\n",
    "    print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conv_exp1_Ati.csv',\n",
       " 'Conv_exp2_Tonson.csv',\n",
       " 'Conv_exp3_Pyae.csv',\n",
       " 'Conv_exp4_Duc.csv',\n",
       " 'Conv_exp5_And.csv',\n",
       " 'Conv_exp6_Sayaka.csv',\n",
       " 'Conv_exp7_Suyoga.csv',\n",
       " 'Conv_exp8_Arti.csv',\n",
       " 'Conv_exp9_Amanda.csv',\n",
       " 'Conv_exp10_Sapna.csv',\n",
       " 'Conv_exp11_Data.csv',\n",
       " 'Conv_exp12_Jirasak.csv',\n",
       " 'Conv_exp13_Max.csv',\n",
       " 'Conv_exp14_Ayush.csv',\n",
       " 'Conv_exp15_Dipesh.csv',\n",
       " 'Conv_exp16_Shashank.csv',\n",
       " 'Conv_exp17_Mi.csv']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of converted data\n",
    "\n",
    "main_path = os.getcwd()\n",
    "all_file = os.listdir(main_path + '/Converted_signal')\n",
    "conv_list = all_file[8:] + all_file[0:8]\n",
    "conv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = main_path + '/Converted_signal/'\n",
    "all_data = []\n",
    "for file in conv_list:\n",
    "    path = file_path + file\n",
    "    df = pd.read_csv(path)\n",
    "    all_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_data)\n",
    "X = np.transpose(X, (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/root/projects/CP/Projects/Signal/label_exp.csv')\n",
    "y = np.array(df['label'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch   #general pytorch\n",
    "import torch.nn as nn  #neural network module\n",
    "import torch.nn.functional as F  #useful functions like softmax, or relu\n",
    "\n",
    "#pip install torchvision; conda install torchvision\n",
    "from torchvision import datasets, transforms  #transforms for image processing\n",
    "from torch.utils.data import DataLoader, Dataset       #dataloader for preparing batch\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 16, 45000) (6, 16, 45000) (11,) (6,)\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=999)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scale transform each channel independently\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[2]):\n",
    "    scalers[i] = MinMaxScaler(feature_range=(-1, 1))\n",
    "    X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i]) \n",
    "    \n",
    "for i in range(X_test.shape[2]):\n",
    "    X_test[:, :, i]  = scalers[i].transform(X_test[:, :, i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14964072424451663 0.2520715131739238\n",
      "-1.0 -1.6923017702572953\n",
      "1.0000000000000004 1.5409476853622228\n"
     ]
    }
   ],
   "source": [
    "print(X_train.mean(), X_test.mean())\n",
    "print(X_train.min(), X_test.min())\n",
    "print(X_train.max(), X_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9255/1504301689.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train)\n",
      "/tmp/ipykernel_9255/1504301689.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train)\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "# Cast data to dataloader for more convenience\n",
    "training_set = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "testing_set = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_batch_size = len(training_set)\n",
    "test_batch_size = len(testing_set)\n",
    "\n",
    "train_loader = DataLoader(training_set, train_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(testing_set, test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eegConv1d(nn.Module):\n",
    "    def __init__(self, input_size = 8, hidden_size=50, out_size=2):\n",
    "        super().__init__()\n",
    "        self.conv1d   = nn.Conv1d(input_size, hidden_size, kernel_size = 3)\n",
    "        self.linear = nn.Linear(50 * 44998, out_size) #taking the last hidden state\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        #seq shape: (11, 16, 45000)\n",
    "        out = self.conv1d(seq)\n",
    "        # out shape: (11, 50, 44998)\n",
    "        out = out.reshape(seq.size(0), -1)\n",
    "        #out shape: (10, 4300)\n",
    "        out = self.linear(out)\n",
    "        #out shape: (4300, 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(999999)\n",
    "device = 'cuda'\n",
    "model = eegConv1d(input_size=16).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 16, 45000]) torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [186], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m train_correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39m y_train)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()  \u001b[39m#.item() give the raw number\u001b[39;00m\n\u001b[1;32m     31\u001b[0m train_acc \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m (train_correct \u001b[39m/\u001b[39m train_total)\n\u001b[0;32m---> 33\u001b[0m train_loss \u001b[39m=\u001b[39m criterion(yhat_train, y_train)\n\u001b[1;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     35\u001b[0m train_loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model.train()\n",
    "\n",
    "#print(f\"Training {type(model).__name__}\")\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    val_total   = 0  \n",
    "    val_correct = 0\n",
    "    train_acc   = 0\n",
    "    val_acc     = 0\n",
    "    \n",
    "    for X_train, y_train in train_loader:\n",
    "    \n",
    "        start_time = time.time()\n",
    "        \n",
    "        X_train = X_train.float().to(device)\n",
    "        y_train = y_train.float().to(device)\n",
    "\n",
    "        print(X_train.shape, X_train.dtype)\n",
    "\n",
    "        yhat_train = model(X_train)\n",
    "        \n",
    "        #train acc\n",
    "        _, predicted = torch.max(yhat_train.data, 1)  #returns max value, indices\n",
    "        train_total += y_train.size(0)  #keep track of total\n",
    "        train_correct += (predicted == y_train).sum().item()  #.item() give the raw number\n",
    "        train_acc = 100 * (train_correct / train_total)\n",
    "        \n",
    "        train_loss = criterion(yhat_train, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        #val accuracy\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val = X_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            yhat_val  = model(X_val)\n",
    "            val_loss     = criterion(yhat_val, y_val)\n",
    "            _, predicted = torch.max(yhat_val.data, 1)  #returns max value, indices\n",
    "            val_total += y_val.size(0)  #keep track of total\n",
    "            val_correct += (predicted == y_val).sum().item()  #.item() give the raw number\n",
    "            val_acc = 100 * (val_correct / val_total)\n",
    "\n",
    "        #save the best model\n",
    "        if val_loss < best_valid_loss:\n",
    "            best_valid_loss = val_loss\n",
    "            #print(\"Model:{} saved.\".format(type(model).__name__))\n",
    "            torch.save(model.state_dict(), '../models/p300conv1d.pth.tar')\n",
    "            best_model_index = i\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {i:2.0f} | Train acc: {train_acc: 2.2f} | \" +\n",
    "          f\"loss: {train_loss:2.2f} | Val acc: {val_acc: 2.2f} | \" +\n",
    "          f\"loss: {val_loss:2.2f} | Time: {epoch_mins}m {epoch_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3189,  0.2071],\n",
       "        [-0.3988, -0.3775],\n",
       "        [-0.4756, -0.3396],\n",
       "        [-0.4002, -0.0655],\n",
       "        [ 0.0720,  0.1953],\n",
       "        [-0.1987,  0.1379],\n",
       "        [ 0.1113,  0.0140],\n",
       "        [-0.1465,  0.0051],\n",
       "        [-0.3568, -0.2592],\n",
       "        [-0.1754,  0.0949],\n",
       "        [-0.1080, -0.5811]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(fake_eeg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d   = nn.Conv1d(16, 50, kernel_size = 3)\n",
    "conv1d = conv1d.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 50, 44996])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = conv1d(fake_eeg_data)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2400\n",
      "    50\n",
      "4499800\n",
      "     2\n",
      "______\n",
      "4502252\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "count_parameters(model) #why 400?, why 40000????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
