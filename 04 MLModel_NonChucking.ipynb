{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_SVM(X,y):\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.utils import shuffle\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    X_shuff,y_shuff = shuffle(X,y)\n",
    "    model = SVC(kernel='rbf')\n",
    "    cross = cross_val_score(model, X_shuff, y_shuff, cv=5, n_jobs=-1)\n",
    "\n",
    "    model = SVC(kernel='rbf')\n",
    "    model.fit(X_shuff, y_shuff)\n",
    "    ans = model.predict(X_shuff)\n",
    "    acc = sum(ans == y_shuff) / len(y_shuff)\n",
    "    return model, acc, cross\n",
    "\n",
    "def model_LR(X,y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.utils import shuffle\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    X_shuff,y_shuff = shuffle(X,y)\n",
    "    model = LogisticRegression()\n",
    "    cross = cross_val_score(model, X_shuff, y_shuff, cv=5, n_jobs=-1)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_shuff, y_shuff)\n",
    "    ans = model.predict(X_shuff)\n",
    "    acc = sum(ans == y_shuff) / len(y_shuff)\n",
    "    return model, acc, cross\n",
    "\n",
    "def model_NB(X,y):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.utils import shuffle\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    X_shuff,y_shuff = shuffle(X,y)\n",
    "    model = GaussianNB()\n",
    "    cross = cross_val_score(model, X_shuff, y_shuff, cv=5, n_jobs=-1)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_shuff, y_shuff)\n",
    "    ans = model.predict(X_shuff)\n",
    "    acc = sum(ans == y_shuff) / len(y_shuff)\n",
    "    return model, acc, cross\n",
    "\n",
    "def model_KNN(X,y):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.utils import shuffle\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    X_shuff,y_shuff = shuffle(X,y)\n",
    "    model = KNeighborsClassifier()\n",
    "    cross = cross_val_score(model, X_shuff, y_shuff, cv=5, n_jobs=-1)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors = 2)\n",
    "    model.fit(X_shuff, y_shuff)\n",
    "    ans = model.predict(X_shuff)\n",
    "    acc = sum(ans == y_shuff) / len(y_shuff)\n",
    "    return model, acc, cross\n",
    "\n",
    "def model_RF(X,y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.utils import shuffle\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    X_shuff,y_shuff = shuffle(X,y)\n",
    "    model = RandomForestClassifier()\n",
    "    cross = cross_val_score(model, X_shuff, y_shuff, cv=5, n_jobs=-1)\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_shuff, y_shuff)\n",
    "    ans = model.predict(X_shuff)\n",
    "    acc = sum(ans == y_shuff) / len(y_shuff)\n",
    "    return model, acc, cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipe(X_test,y_test,model):\n",
    "    from sklearn.metrics import accuracy_score  \n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    model = model\n",
    "    y_pred = model.predict(X_test)\n",
    "    target_names = ['without Stress', 'with Stress']\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    # crp = classification_report(y_test,y_pred, target_names=target_names)\n",
    "    print(\"Test Acc :\",acc)\n",
    "    # print(\"classification_report : \\n\",crp)\n",
    "    # print(sns.heatmap(confusion_matrix(y_test,y_pred),annot=True))\n",
    "    # plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipe(X_train, X_test, y_train, y_test):\n",
    "    X,y = X_train.copy(),y_train.copy()\n",
    "    model, acc, cross = model_SVM(X,y)\n",
    "    print(f'{model}\\n Train Acc : {acc:.4f} Score :{cross.mean():.4f}',end=' ')\n",
    "    test_pipe(X_test, y_test ,model)\n",
    "    X,y = X_train.copy(),y_train.copy()\n",
    "    model, acc, cross = model_LR(X,y) \n",
    "    print(f'{model}\\n Train Acc : {acc:.4f} Score :{cross.mean():.4f}',end=' ')\n",
    "    # print('\\nWeight',model.coef_)\n",
    "    test_pipe(X_test, y_test ,model)\n",
    "    X,y = X_train.copy(),y_train.copy()\n",
    "    model, acc, cross = model_NB(X,y)\n",
    "    print(f'{model}\\n Train Acc : {acc:.4f} Score :{cross.mean():.4f}',end=' ')\n",
    "    test_pipe(X_test, y_test ,model)\n",
    "    X,y = X_train.copy(),y_train.copy()\n",
    "    model, acc, cross = model_KNN(X,y)\n",
    "    print(f'{model}\\n Train Acc : {acc:.4f} Score :{cross.mean():.4f}',end=' ')\n",
    "    test_pipe(X_test, y_test ,model)\n",
    "    X,y = X_train.copy(),y_train.copy()\n",
    "    model, acc, cross = model_RF(X,y)\n",
    "    print(f'{model}\\n Train Acc : {acc:.4f} Score :{cross.mean():.4f}',end=' ')\n",
    "    test_pipe(X_test, y_test ,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 13), (17,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_asy = pd.read_csv('./data/PSDAsymmetryData.csv')\n",
    "df_asy.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "y = pd.read_csv('./data/label_exp.csv')\n",
    "y = np.array(y['label'])\n",
    "df_asy.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 13), (4, 13), (13,), (4,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_asy, y, test_size=0.2, random_state=999)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = ['Alpha_frontal','Alpha_temporal','Alpha_asymmetry']\n",
    "gamma = ['Relative_gamma']\n",
    "beta = ['Beta_Frontal','Beta_temporal']\n",
    "\n",
    "alpha_beta = ['Alpha_frontal','Alpha_temporal','Alpha_asymmetry','Beta_Frontal','Beta_temporal']\n",
    "alpha_gamma = ['Alpha_frontal','Alpha_temporal','Alpha_asymmetry','Relative_gamma']\n",
    "beta_gamma = ['Beta_Frontal','Beta_temporal','Relative_gamma']\n",
    "\n",
    "alpha_beta_gamma = ['Alpha_frontal','Alpha_temporal','Alpha_asymmetry','Beta_Frontal','Beta_temporal','Relative_gamma']\n",
    "\n",
    "type_list = [alpha,gamma,beta,alpha_beta,alpha_gamma,beta_gamma,alpha_beta_gamma]\n",
    "name_list = ['alpha','gamma','alpha_beta','alpha_gamma','beta_gamma','alpha_beta_gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Slow</th>\n",
       "      <th>Low_beta</th>\n",
       "      <th>Relative_gamma</th>\n",
       "      <th>Alpha_frontal</th>\n",
       "      <th>Alpha_temporal</th>\n",
       "      <th>Alpha_asymmetry</th>\n",
       "      <th>Beta_Frontal</th>\n",
       "      <th>Beta_temporal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.586312</td>\n",
       "      <td>6.707970</td>\n",
       "      <td>5.174905</td>\n",
       "      <td>-1.488369</td>\n",
       "      <td>-5.540987</td>\n",
       "      <td>5.855575</td>\n",
       "      <td>1.308892</td>\n",
       "      <td>-1.056775</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.117401</td>\n",
       "      <td>0.122368</td>\n",
       "      <td>-0.067948</td>\n",
       "      <td>0.032048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.721077</td>\n",
       "      <td>6.705430</td>\n",
       "      <td>10.163864</td>\n",
       "      <td>-0.589365</td>\n",
       "      <td>-2.945416</td>\n",
       "      <td>7.988509</td>\n",
       "      <td>0.665451</td>\n",
       "      <td>-2.712183</td>\n",
       "      <td>-0.044676</td>\n",
       "      <td>-0.020332</td>\n",
       "      <td>-0.065009</td>\n",
       "      <td>-0.841200</td>\n",
       "      <td>0.088445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.259280</td>\n",
       "      <td>9.024825</td>\n",
       "      <td>11.389089</td>\n",
       "      <td>14.575796</td>\n",
       "      <td>17.806796</td>\n",
       "      <td>10.434642</td>\n",
       "      <td>12.539912</td>\n",
       "      <td>0.585992</td>\n",
       "      <td>-0.144605</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>-0.129464</td>\n",
       "      <td>-0.195230</td>\n",
       "      <td>0.005924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.045821</td>\n",
       "      <td>6.127062</td>\n",
       "      <td>3.475107</td>\n",
       "      <td>-4.441812</td>\n",
       "      <td>-11.033523</td>\n",
       "      <td>4.134019</td>\n",
       "      <td>-1.333435</td>\n",
       "      <td>-0.374678</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>-0.057762</td>\n",
       "      <td>-0.049863</td>\n",
       "      <td>0.095987</td>\n",
       "      <td>0.576313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.840564</td>\n",
       "      <td>5.948327</td>\n",
       "      <td>4.846019</td>\n",
       "      <td>-0.609308</td>\n",
       "      <td>-9.052312</td>\n",
       "      <td>5.128139</td>\n",
       "      <td>3.237279</td>\n",
       "      <td>-0.566501</td>\n",
       "      <td>-0.128629</td>\n",
       "      <td>-0.025831</td>\n",
       "      <td>-0.154461</td>\n",
       "      <td>1.700731</td>\n",
       "      <td>0.252154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Delta     Theta      Alpha       Beta      Gamma       Slow   Low_beta  \\\n",
       "0  19.586312  6.707970   5.174905  -1.488369  -5.540987   5.855575   1.308892   \n",
       "1  16.721077  6.705430  10.163864  -0.589365  -2.945416   7.988509   0.665451   \n",
       "2  13.259280  9.024825  11.389089  14.575796  17.806796  10.434642  12.539912   \n",
       "3  14.045821  6.127062   3.475107  -4.441812 -11.033523   4.134019  -1.333435   \n",
       "4  13.840564  5.948327   4.846019  -0.609308  -9.052312   5.128139   3.237279   \n",
       "\n",
       "   Relative_gamma  Alpha_frontal  Alpha_temporal  Alpha_asymmetry  \\\n",
       "0       -1.056775       0.004968        0.117401         0.122368   \n",
       "1       -2.712183      -0.044676       -0.020332        -0.065009   \n",
       "2        0.585992      -0.144605        0.015141        -0.129464   \n",
       "3       -0.374678       0.007900       -0.057762        -0.049863   \n",
       "4       -0.566501      -0.128629       -0.025831        -0.154461   \n",
       "\n",
       "   Beta_Frontal  Beta_temporal  \n",
       "0     -0.067948       0.032048  \n",
       "1     -0.841200       0.088445  \n",
       "2     -0.195230       0.005924  \n",
       "3      0.095987       0.576313  \n",
       "4      1.700731       0.252154  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_asy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 3) (4, 3) (13,) (4,)\n",
      "(13, 3) (4, 3)\n",
      "alpha_beta\n",
      "SVC()\n",
      " Train Acc : 0.6923 Score :0.6000 Test Acc : 0.5\n",
      "LogisticRegression()\n",
      " Train Acc : 0.6154 Score :0.6000 Test Acc : 0.5\n",
      "GaussianNB()\n",
      " Train Acc : 0.6923 Score :0.6333 Test Acc : 0.25\n",
      "KNeighborsClassifier(n_neighbors=2)\n",
      " Train Acc : 0.7692 Score :0.4667 Test Acc : 0.5\n",
      "RandomForestClassifier()\n",
      " Train Acc : 1.0000 Score :0.7333 Test Acc : 0.5\n",
      "-------------------------------\n",
      "(13, 1) (4, 1) (13,) (4,)\n",
      "(13, 1) (4, 1)\n",
      "alpha\n",
      "SVC()\n",
      " Train Acc : 0.6923 Score :0.6000 Test Acc : 0.5\n",
      "LogisticRegression()\n",
      " Train Acc : 0.6923 Score :0.4667 Test Acc : 0.5\n",
      "GaussianNB()\n",
      " Train Acc : 0.6154 Score :0.5000 Test Acc : 0.5\n",
      "KNeighborsClassifier(n_neighbors=2)\n",
      " Train Acc : 0.6154 Score :0.4000 Test Acc : 0.5\n",
      "RandomForestClassifier()\n",
      " Train Acc : 1.0000 Score :0.3667 Test Acc : 0.25\n",
      "-------------------------------\n",
      "(13, 2) (4, 2) (13,) (4,)\n",
      "(13, 2) (4, 2)\n",
      "gamma\n",
      "SVC()\n",
      " Train Acc : 0.6154 Score :0.5333 Test Acc : 0.5\n",
      "LogisticRegression()\n",
      " Train Acc : 0.6154 Score :0.4667 Test Acc : 0.25\n",
      "GaussianNB()\n",
      " Train Acc : 0.8462 Score :0.6667 Test Acc : 0.75\n",
      "KNeighborsClassifier(n_neighbors=2)\n",
      " Train Acc : 0.7692 Score :0.4667 Test Acc : 1.0\n",
      "RandomForestClassifier()\n",
      " Train Acc : 1.0000 Score :0.5333 Test Acc : 0.75\n",
      "-------------------------------\n",
      "(13, 5) (4, 5) (13,) (4,)\n",
      "(13, 5) (4, 5)\n",
      "beta_gamma\n",
      "SVC()\n",
      " Train Acc : 0.6154 Score :0.6000 Test Acc : 0.5\n",
      "LogisticRegression()\n",
      " Train Acc : 0.5385 Score :0.4667 Test Acc : 0.5\n",
      "GaussianNB()\n",
      " Train Acc : 0.8462 Score :0.7000 Test Acc : 0.5\n",
      "KNeighborsClassifier(n_neighbors=2)\n",
      " Train Acc : 0.9231 Score :0.5667 Test Acc : 0.75\n",
      "RandomForestClassifier()\n",
      " Train Acc : 1.0000 Score :0.5667 Test Acc : 0.75\n",
      "-------------------------------\n",
      "(13, 4) (4, 4) (13,) (4,)\n",
      "(13, 4) (4, 4)\n",
      "alpha_gamma\n",
      "SVC()\n",
      " Train Acc : 0.6154 Score :0.6000 Test Acc : 0.5\n",
      "LogisticRegression()\n",
      " Train Acc : 0.6923 Score :0.4333 Test Acc : 0.5\n",
      "GaussianNB()\n",
      " Train Acc : 0.6923 Score :0.6000 Test Acc : 0.25\n",
      "KNeighborsClassifier(n_neighbors=2)\n",
      " Train Acc : 0.7692 Score :0.5333 Test Acc : 0.5\n",
      "RandomForestClassifier()\n",
      " Train Acc : 1.0000 Score :0.6667 Test Acc : 0.5\n",
      "-------------------------------\n",
      "(13, 3) (4, 3) (13,) (4,)\n",
      "(13, 3) (4, 3)\n",
      "alpha_beta\n",
      "SVC()\n",
      " Train Acc : 0.6154 Score :0.6000 Test Acc : 0.5\n",
      "LogisticRegression()\n",
      " Train Acc : 0.6923 Score :0.3000 Test Acc : 0.0\n",
      "GaussianNB()\n",
      " Train Acc : 0.8462 Score :0.5333 Test Acc : 0.75\n",
      "KNeighborsClassifier(n_neighbors=2)\n",
      " Train Acc : 0.8462 Score :0.5333 Test Acc : 0.5\n",
      "RandomForestClassifier()\n",
      " Train Acc : 1.0000 Score :0.5333 Test Acc : 0.75\n",
      "-------------------------------\n",
      "(13, 6) (4, 6) (13,) (4,)\n",
      "(13, 6) (4, 6)\n",
      "alpha_beta_gamma\n",
      "SVC()\n",
      " Train Acc : 0.6154 Score :0.6000 Test Acc : 0.5\n",
      "LogisticRegression()\n",
      " Train Acc : 0.6154 Score :0.3667 Test Acc : 0.25\n",
      "GaussianNB()\n",
      " Train Acc : 0.8462 Score :0.7000 Test Acc : 0.5\n",
      "KNeighborsClassifier(n_neighbors=2)\n",
      " Train Acc : 0.8462 Score :0.6333 Test Acc : 0.5\n",
      "RandomForestClassifier()\n",
      " Train Acc : 1.0000 Score :0.6000 Test Acc : 0.5\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "i = 0\n",
    "for type in type_list:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_asy[type], y, test_size=0.2, random_state=999)\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    X_train_scaled = np.zeros_like(X_train)\n",
    "    X_test_scaled = np.zeros_like(X_test)\n",
    "    print(X_train_scaled.shape, X_test_scaled.shape)\n",
    "\n",
    "    scalers = {}\n",
    "    for i in range(X_train.shape[1]):\n",
    "        scalers[i] = MinMaxScaler(feature_range=(-1, 1))\n",
    "        X_minmax = scalers[i].fit_transform(X_train[:,i].reshape(-1, 1))\n",
    "        X_train_scaled[:,i] = X_minmax[:,0]\n",
    "\n",
    "    for i in range(X_test.shape[1]):\n",
    "        X_test_minmax = scalers[i].transform(X_test[:,i].reshape(-1, 1))\n",
    "        X_test_scaled[:,i] = X_test_minmax[:,0]\n",
    "\n",
    "    print(name_list[i])\n",
    "    train_pipe(X_train, X_test, y_train, y_test)\n",
    "    i = i + 1\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need chunking process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
