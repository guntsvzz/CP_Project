{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "pickle.format_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = os.getcwd()\n",
    "all_file = os.listdir()\n",
    "file_name = list()\n",
    "for file in all_file:\n",
    "    if file[0:3] == 'exp':\n",
    "        file_name.append(file)\n",
    "file_name = sorted(file_name)\n",
    "file = file_name[8:] + file_name[0:8]\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(main_path + '/' + file[0])\n",
    "df1 = df1.drop(columns=['Unnamed: 0', '0', '17', '18', '19', '20', '21', '22',\n",
    "       '23', '24', '25', '26', '27', '28', '29', '30', '31'])\n",
    "df1.columns = ['Fp1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'T3', 'C3', 'C4', 'T4', 'T5', 'P3', 'P4', 'T6', 'O1', 'O2']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns and save it into the new file.\n",
    "for i in range(len(file)):\n",
    "    converted_signal_path = main_path + '/Converted_signal/' + 'Conv_' + file[i]\n",
    "    df = pd.read_csv(main_path + '/' + file[i])\n",
    "    df = df.drop(columns=['Unnamed: 0', '0', '17', '18', '19', '20', '21', '22',\n",
    "        '23', '24', '25', '26', '27', '28', '29', '30', '31'])\n",
    "    df.columns = ['Fp1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'T3', 'C3', 'C4', 'T4', 'T5', 'P3', 'P4', 'T6', 'O1', 'O2']\n",
    "    df = df.set_index(df.columns[0])\n",
    "    df.to_csv(converted_signal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_raw(df):\n",
    "    ch_names = ['Fp1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'T3', 'C3', 'C4', 'T4', 'T5', 'P3', 'P4', 'T6', 'O1', 'O2']\n",
    "    ch_types = ['eeg'] * len(ch_names)\n",
    "    df = df.T\n",
    "    sampling_rate = 250 #Hz\n",
    "    info = mne.create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sampling_rate)\n",
    "    raw = mne.io.RawArray(df, info)\n",
    "    raw.set_montage('standard_1020')\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import Epochs, find_events\n",
    "\n",
    "def getEpochs(raw, event_id, tmin, tmax, picks):\n",
    "\n",
    "    #epoching\n",
    "    events = find_events(raw)\n",
    "    epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                    tmin=tmin, tmax=tmax, baseline=None, preload=True,verbose=False, picks=picks)  #8 channels\n",
    "    print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conv_exp1_Ati.csv',\n",
       " 'Conv_exp2_Tonson.csv',\n",
       " 'Conv_exp3_Pyae.csv',\n",
       " 'Conv_exp4_Duc.csv',\n",
       " 'Conv_exp5_And.csv',\n",
       " 'Conv_exp6_Sayaka.csv',\n",
       " 'Conv_exp7_Suyoga.csv',\n",
       " 'Conv_exp8_Arti.csv',\n",
       " 'Conv_exp9_Amanda.csv',\n",
       " 'Conv_exp10_Sapna.csv',\n",
       " 'Conv_exp11_Data.csv',\n",
       " 'Conv_exp12_Jirasak.csv',\n",
       " 'Conv_exp13_Max.csv',\n",
       " 'Conv_exp14_Ayush.csv',\n",
       " 'Conv_exp15_Dipesh.csv',\n",
       " 'Conv_exp16_Shashank.csv',\n",
       " 'Conv_exp17_Mi.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of converted data\n",
    "\n",
    "main_path = os.getcwd()\n",
    "all_file = os.listdir(main_path + '/Converted_signal')\n",
    "conv_list = all_file[8:] + all_file[0:8]\n",
    "conv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = main_path + '/Converted_signal/'\n",
    "all_data = []\n",
    "for file in conv_list:\n",
    "    path = file_path + file\n",
    "    df = pd.read_csv(path)\n",
    "    all_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_data)\n",
    "X = np.transpose(X, (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/root/projects/CP/Projects/Signal/label_exp.csv')\n",
    "y = np.array(df['label'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch   #general pytorch\n",
    "import torch.nn as nn  #neural network module\n",
    "import torch.nn.functional as F  #useful functions like softmax, or relu\n",
    "\n",
    "#pip install torchvision; conda install torchvision\n",
    "from torchvision import datasets, transforms  #transforms for image processing\n",
    "from torch.utils.data import DataLoader, Dataset       #dataloader for preparing batch\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 16, 45000) (4, 16, 45000) (13,) (4,)\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=999)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 16, 45000) (2, 16, 45000) (11,) (2,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=999)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scale transform each channel independently\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[2]):\n",
    "    scalers[i] = MinMaxScaler(feature_range=(-1, 1))\n",
    "    X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i]) \n",
    "\n",
    "for i in range(X_val.shape[2]):\n",
    "    X_val[:, :, i]   = scalers[i].transform(X_val[:, :, i])     \n",
    "    \n",
    "for i in range(X_test.shape[2]):\n",
    "    X_test[:, :, i]  = scalers[i].transform(X_test[:, :, i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17394497961134747 -0.34915787177665036 0.12544181839149665\n",
      "-1.0 -5.276083248178158 -1.6923017702572953\n",
      "1.0000000000000004 0.9985499015664524 1.848048482814936\n"
     ]
    }
   ],
   "source": [
    "print(X_train.mean(), X_val.mean(), X_test.mean())\n",
    "print(X_train.min(), X_val.min(), X_test.min())\n",
    "print(X_train.max(), X_val.max(), X_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "X_val_tensor = torch.tensor(X_val)\n",
    "y_val_tensor = torch.tensor(y_val)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "# Cast data to dataloader for more convenience\n",
    "training_set = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "testing_set = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "validation_set = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_batch_size = 5\n",
    "val_batch_size = len(validation_set)\n",
    "test_batch_size = len(testing_set)\n",
    "\n",
    "train_loader = DataLoader(training_set, train_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(validation_set, val_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testing_set, test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 50, 22499])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_eeg_data = torch.randn((11, 50, 44998)) #(batch_size, channels, length)\n",
    "maxpool1d = nn.MaxPool1d(2,2)\n",
    "out = maxpool1d(fake_eeg_data)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eegConv1d(nn.Module):\n",
    "    def __init__(self, input_size = 8, out_size=2):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(input_size, 50, kernel_size = 3)\n",
    "        self.c2 = nn.Conv1d(50, 30, kernel_size = 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.maxpool1d = nn.MaxPool1d(2,2)\n",
    "        self.linear = nn.Linear(30 * 22497, out_size) #taking the last hidden state\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        #convo layer 8 -> 50 -> 30\n",
    "        #seq shape: (11, 50, 45000)\n",
    "        out = self.c1(seq)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        # out shape: (11, 50, 44998)\n",
    "        out = self.maxpool1d(out)\n",
    "        # out shape: (11, 50, 22499)\n",
    "        out = self.c2(out)\n",
    "        out = self.relu(out)\n",
    "        # out shape: (11, 30, 22496)\n",
    "        out = out.reshape(seq.size(0), -1)\n",
    "        #out shape: (30, 30*22496)\n",
    "        out = self.linear(out)\n",
    "        #out shape: (30*22496, 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(999999)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = eegConv1d(input_size=16).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Train acc:  72.73 | loss: 0.00000 | Val acc:  33.33 | loss: 573.93500 | Time: 0m 0s\n",
      "Epoch:  1 | Train acc:  81.82 | loss: 4448.88477 | Val acc:  83.33 | loss: 0.00000 | Time: 0m 0s\n",
      "Epoch:  2 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 1035.77136 | Time: 0m 0s\n",
      "Epoch:  3 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 1409.53467 | Time: 0m 0s\n",
      "Epoch:  4 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 1672.25049 | Time: 0m 0s\n",
      "Epoch:  5 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 1895.83105 | Time: 0m 0s\n",
      "Epoch:  6 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2102.13818 | Time: 0m 0s\n",
      "Epoch:  7 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2263.89429 | Time: 0m 0s\n",
      "Epoch:  8 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2403.82666 | Time: 0m 0s\n",
      "Epoch:  9 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2509.31812 | Time: 0m 0s\n",
      "Epoch: 10 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2600.09644 | Time: 0m 0s\n",
      "Epoch: 11 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2656.66455 | Time: 0m 0s\n",
      "Epoch: 12 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2708.98291 | Time: 0m 0s\n",
      "Epoch: 13 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2739.02490 | Time: 0m 0s\n",
      "Epoch: 14 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2784.75098 | Time: 0m 0s\n",
      "Epoch: 15 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2812.86621 | Time: 0m 0s\n",
      "Epoch: 16 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2829.42773 | Time: 0m 0s\n",
      "Epoch: 17 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2819.82837 | Time: 0m 0s\n",
      "Epoch: 18 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2853.45850 | Time: 0m 0s\n",
      "Epoch: 19 | Train acc:  100.00 | loss: 0.00000 | Val acc:  50.00 | loss: 2837.30420 | Time: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model.train()\n",
    "\n",
    "#print(f\"Training {type(model).__name__}\")\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    val_total   = 0  \n",
    "    val_correct = 0\n",
    "    train_acc   = 0\n",
    "    val_acc     = 0\n",
    "    \n",
    "    for X_train, y_train in train_loader:\n",
    "    \n",
    "        start_time = time.time()\n",
    "        \n",
    "        X_train = X_train.float().to(device)\n",
    "        y_train = y_train.type(torch.LongTensor).to(device)\n",
    "\n",
    "        #print(X_train.shape, X_train.dtype)\n",
    "\n",
    "        yhat_train = model(X_train)\n",
    "        \n",
    "        #train acc\n",
    "        _, predicted = torch.max(yhat_train.data, 1)  #returns max value, indices\n",
    "        train_total += y_train.size(0)  #keep track of total\n",
    "        train_correct += (predicted == y_train).sum().item()  #.item() give the raw number\n",
    "        train_acc = 100 * (train_correct / train_total)\n",
    "        \n",
    "        #print(y_train.shape, y_train.dtype)\n",
    "        \n",
    "        train_loss = criterion(yhat_train, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        #val accuracy\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val = X_val.float().to(device)\n",
    "            y_val = y_val.type(torch.LongTensor).to(device)\n",
    "            yhat_val  = model(X_val)\n",
    "            val_loss     = criterion(yhat_val, y_val)\n",
    "            _, predicted = torch.max(yhat_val.data, 1)  #returns max value, indices\n",
    "            val_total += y_val.size(0)  #keep track of total\n",
    "            val_correct += (predicted == y_val).sum().item()  #.item() give the raw number\n",
    "            val_acc = 100 * (val_correct / val_total)\n",
    "\n",
    "        #save the best model\n",
    "        if val_loss < best_valid_loss:\n",
    "            best_valid_loss = val_loss\n",
    "            #print(\"Model:{} saved.\".format(type(model).__name__))\n",
    "            torch.save(model.state_dict(), '/root/projects/CP/Projects/Model/chornicconvo1d.pth.tar')\n",
    "            best_model_index = i\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {i:2.0f} | Train acc: {train_acc: 2.2f} | \" +\n",
    "          f\"loss: {train_loss:2.5f} | Val acc: {val_acc: 2.2f} | \" +\n",
    "          f\"loss: {val_loss:2.5f} | Time: {epoch_mins}m {epoch_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(X_test_tensor.float().to(device))\n",
    "#testloss = criterion(yhat, y_test_tensor.type(torch.LongTensor).to(device))\n",
    "_, predicted = torch.max(yhat.data, 1)\n",
    "\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
